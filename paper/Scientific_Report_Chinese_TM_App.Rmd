---
title: 'Whats driving chinese news'
author: 'David Schulze, Eyayaw Teka Beze, Nils Paffen'
subtitle: "How news correlates with the economy "
type: "Scientifc Report"
discipline: "Phd Programm RWI, VWL M.Sc.,"
date: "today"
studid: "3071594, ID David, ID Eyayaw"
supervisors: "Martin Christopher Arnold and Alexander Gerber"
ssemester: "3"
estdegree_emester: "Winter Term 2020"
deadline: "Apr. 7th 2020"
header-includes:
   # fix for latex unicode error with Chinese characters
   - \usepackage{CJKutf8}
   - \usepackage[utf8]{inputenc}
output:
  pdf_document:
    keep_tex: yes
    template: template.tex
    fig_caption: yes
    citation_package: biblatex
    number_sections: true
toc: true
lot: true
lof: true
graphics: true
biblio-title: References
fontsize: 12pt
geometry: lmargin = 3 cm,rmargin = 2.5cm,tmargin=2.5cm,bmargin=2.5cm
biblio-files: references.bib
classoption: a4paper
---

% This command is used by pandoc when create lists and is defined in pandoc's default latex template
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}



# Introduction (David)


## Motivation

Ever since it's establishment in 1948 as the Chinese Communist Party's (CPC) officially designated publication organ, and especially since it announced the foundation of the People's Republic by Mao Zedong on October 1st, 1949, the People's Daily newspaper (also known as Renmin Ribao or RMRB) has been an object of the highest interest for anyone interested in modern China. It is safe to say that it's front page is that of the most widely published newspapers in Chinese and it's the most widely read. This amount of attention and it's clear designation as voice of the CPC have made it an invaluable source for information on China's ruling elite's communication with the masses. In times of crisis, even tiny changes in placing, formatting or wording are chosen and interpreted with extreme scrutiny \citep{tan1990}. The reason for this is on the one hand the need for some form of discussion involving the government and the educated citizenry \citep{kuhn2002}, but also the sensitivity of certain topics, also called censorship.

In the past, close reading and an intimate knowledge of the Chinese language were the only tools available to researchers interested in this publication. Even the most well-read scholars of modern China will have to admit that reading the paper daily and in it's entirety, even just the front page, will be a thankless undertaking. Most articles are official statements and collections of facts about the activites of leaders, or plain positive messages about some aspect about the nation, also called, by the CPC themselves, propaganda. The nuances that to detect require years of study are difficult to check against factual evidence, short of spending hours of reading yourself. Only rarely are messages communicated as clearly, as back on the founding day of the People's Republic.

This presents in our view a very urgent opportunity for automated data mining. Unlike historic literary corpora like the works of Shakespeare that can be analysed by generations of scholars, news is by its nature fleeting and often needs to be analysed in a hurry and theories tested as events unfold.

To test our idea for an automated evaluation of People's Daily articles themselves and in context of economic data, we proposed the development of an app, that would automate the task of updating the news corpora and economic data, as well as some descriptive and basic analytical steps used in quantitative text analysis. To make these results available to non-Chinese speakers, we include a simple translation routine, that gives the most common word for word translation, even if not the meaning of entire articles or sentences.

We stress that this will in no way substitute any qualitative reading, knowledge of Chinese politics, expertise in Chinese language or even text mining of the news in general. But to be able to quickly develop and test quantitative hypotheses about Chinese news and its relation to economic data, might be a useful tool on the way to further research and in-depth text mining.

## Newspaper Structure

For the app we focus on the first two pages, because the first is arguably one of the most important daily publications in China, and the second might offer interesting contrasts, because it is aimed at a different audience, while significance diminishes rapidly with increasing page count: The latter pages of this leading CPC publications are actually full-page advertisements for private company's products, among others.

The first page's layout is different every day, according to the needs of the editors: The documentory function implies that a lot of information is squeezed into a tight space. Articles may be reduced, truncated or pushed to the side of the page to make room for symbolic pictures ^[See for example the pictures displaying national remembrance of the "martyrs sacrificed in the struggle against Covid-19" with bowing national leaders and the lowered flag in black and white [front page from 2020-04-05](http://paper.people.com.cn/rmrb/html/2020-04/05/nw.D110000renmrb_20200405_1-01.htm)] and voluminous leading articles. On the other end of the spectrum are crowded front pages with up to 15 tiny articles commemorating each meeting of a tightly packed international summit schedule, with 15 headlines reading: "Xi Jinping meets (insert name of foreign national head of state)" ^[[front page from 2020-04-26](http://paper.people.com.cn/rmrb/html/2019-04/26/nbs.D110000renmrb_01.htm)].

How can we ever expect to extract useful information from such a data source? Well, for nuances in reporting to have any impact, they have to be special or deviating in some way from an established norm. By gathering data over hundreds of days, we hope that these patterns and deviations will become visible. Also, comparing subsets of data such as front and second page, reporting before and after a certain date, commonalities will be filtered out and differences highlighted. Since our data cover the year 2019 and the first months of the Covid-19 outbreak that was first documented officially by authorities in Wuhan, Hubei Province China on 2020-01-05 ^["Wuhan Health Commission report on the situation concerning a viral lung disease with unknown origins", [wjw.wuhan.gov.cn](http://wjw.wuhan.gov.cn/front/web/showDetail/2020010509020)], this constitutes an opportunity to evaluate how this major shock is covered and news compare before and after the outbreak was acknowledged.

While text mining and natural language processing algorithms have matured extremely in the contexts of machine learning and applications for example in online search, the technology barrier has limited it's adoption in the social sciences. To make basic results accessible and reproducible, is finally a large motivation for the creation of this app.



# Data Sources 

## Text Data (Nils)

- short and general info

About one year and three month of data. Scraped from the free archive of [Peoples Daily](http://paper.people.com.cn/rmrb). A more detailed explanation of the scraping process is added in the method section \ref{sec:Methods} The app includes an automated updating routine that expands the database scraping directly from paper.people.com.cn.

## Economic Data (Eyayaw)



# Construction of the Application

## Concept (David)
- introduce file structure
- intruduce app concept in detail, maybe use ((Scrivner, Olga & Davis, Jefferson. (2017). Interactive Text Mining Suite: Data Visualization for Literary Studies)) available at http://ceur-ws.org/Vol-1786/scrivner.pdf for cool info on shiny text mining.


## Scraping process for original database (Nils)

- idea, process and issues we encountered


## Translation from Chinese (David)
To make the app basically usable for non-Chinese speakers, a translation feature was introduced. Because Chinese has no spaces, we needed to use a NLP algorithm ((quote: jiebaR)), so that in the article texts, spaces could be placed between words to separate them. Unique words were added to a Chinese dictionary. Each word was in turn passed on to the translation API from Yandex. This yields in most cases a reliable one-word translation. Alternative translations were beyond the scope of this app, and for in depth analysis, a knowledge of Chinese or at least use of more translation tools is necessary. This dictionary is exported in .rds and .csv files for further use. The articles are then translated word for word. This will speed up using the app for text mining with English words, even if it does not give a useful translation of the complete texts.

### Some additional remarks:

To reduce use of the Yandex translation API (which has limited free bandwith) in each update, only new words are translated and added. This allowed an approximation of the range of unique words used. For illustration: Translating all the unique words (words includes here names, idioms, technological terms, etc.) yielded at least 50150 unique words for the first pages of all of 2019. The second pages of 2019 added 16393 new words. For the first three months, we found still 3228 new words for page 1 and 2350 new words for page 2. Even when allowing for misclassification by the NLP algorithm (sometimes words might be recorded as separately and again as a compound), this suggests that the news needs plenty of new words to adapt to current developments, e.g. "Covid-19".

Another aspect of the dictionary: While all Chinese words are unique, the English translation yielded around 25000 duplicated entries. This means that users searching for example for "satellite" will find hits for "Wei Xing", "Ke Weixing" and "Renzao Wei Xing", which all carry that meaning, improving the accuracy of text mining.


## Economic data retrieval (Eyayaw)

- Where, what and how did we get it.

- This can be very short.


## Exploratory statistics, visualisation, and text mining (Eyayaw)
Start with simplest descriptives and plots, e.g.:

- descriptive plots for the data: article frequencies etc.
The data reveal that there are systematic differences between the first and second pages. ((insert article frequency plots from descriptives))
For both 2019 and 2020, the first page has several outliers with over 10 articles per page, while the second page has no more than 9 articles per page. This is mostly due to the coverage over important events which are covered in many small articles on the front page, e.g Xi Jinping's meetings with world leaders at international summits.

- most common non-stop words with frequencies

- compare pre- and post-corona common words

- pre-post word clouds with translated words

- two-word correlation

- time-series frequency plots (very important)

- n-grams (possiblly useful packages: JSTORr, ngram, NSP, WordStat)


Optional:

- bigram graph

- two-word correlation with phi-coefficient

- lda/topic model (very optional)

Do not:

- sentiment analysis


## Shiny user interface (David)



# Results

Here we should show some of the results of our application. As discussed before COVID-19 will be most likely the centre of our examples but maybe we can show here the mentioned theory of the shadow page as well



# Discussion (David)

How could we improve the app? Extend the archive? Add more economic data? Implement some other statistical information?

Encrypted server version



# Conclusion (David)

Summary of our application and our results. Do we have plans to expand and update the app further in the near future?



Just an idea, because they want it scientific, let's include a bunch of references to the data mining book, etc., just if you find some that would make sense.

\newpage











