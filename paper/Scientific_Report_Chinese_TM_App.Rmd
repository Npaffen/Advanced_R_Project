---
title: 'Whats driving chinese news'
author: 'David Schulze, Eyayaw Teka Beze, Nils Paffen'
subtitle: "How news correlates with the economy "
type: "Scientifc Report"
discipline: "Phd Programm RWI, VWL M.Sc.,"
date: "today"
studid: "3071594, ID David, ID Eyayaw"
supervisors: "Martin Christopher Arnold and Alexander Gerber"
ssemester: "3"
estdegree_emester: "Winter Term 2020"
deadline: "Apr. 7th 2020"
output:
  pdf_document:
    keep_tex: yes
    template: template.tex
    fig_caption: yes
    citation_package: biblatex
    number_sections: true
toc: true
lot: true
lof: true
graphics: true
biblio-title: References
fontsize: 12pt
geometry: lmargin = 3 cm,rmargin = 2.5cm,tmargin=2.5cm,bmargin=2.5cm
biblio-files: references.bib
classoption: a4paper
---

% This command is used by pandoc when create lists and is defined in pandoc's default latex template
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

% fix for latex unicode error with Chinese characters
```{r results = "hide"}
# devtools::install_github("rstudio/rmarkdown")
```


# Introduction (David)

- short intro

- motivation: historic impact of news

- intro to structure of People's Daily

- motivation: People's Daily is the governing Chinese Communist Party's Major Outlet


## Current Situation in China (David)

- End of 2019: Trade war with the US

- 2020: Covid-19



# Data Sources 

## Text Data (Nils)

- short and general info

About one year and three month of data. Scraped from the free archive of [Peoples Daily](http://paper.people.com.cn/rmrb). A more detailed explanation of the scraping process is added in the method section \ref{sec:Methods} The app includes an automated updating routine that expands the database scraping directly from paper.people.com.cn.

## Economic Data (Eyayaw)



# Construction of the Application

## Scraping process for original database (Nils)

- idea, process and issues we encountered


## Translation from Chinese (David)
To make the app basically usable for non-Chinese speakers, a translation feature was introduced. Because Chinese has no spaces, we needed to use a NLP algorithm ((quote: jiebaR)), so that in the article texts, spaces could be placed between words to separate them. Unique words were added to a Chinese dictionary. Each word was in turn passed on to the translation API from Yandex. This yields in most cases a reliable one-word translation. Alternative translations were beyond the scope of this app, and for in depth analysis, a knowledge of Chinese or at least use of more translation tools is necessary. This dictionary is exported in .rds and .csv files for further use. The articles are then translated word for word. This will speed up using the app for text mining with English words, even if it does not give a useful translation of the complete texts.

### Some additional remarks:

To reduce use of the Yandex translation API (which has limited free bandwith) in each update, only new words are translated and added. This allowed an approximation of the range of unique words used. For illustration: Translating all the unique words (words includes here names, idioms, technological terms, etc.) yielded at least 50150 unique words for the first pages of all of 2019. The second pages of 2019 added 16393 new words. For the first three months, we found still 3228 new words for page 1 and 2350 new words for page 2. Even when allowing for misclassification by the NLP algorithm (sometimes words might be recorded as separately and again as a compound), this suggests that the news needs plenty of new words to adapt to current developments, e.g. "Covid-19".

Another aspect of the dictionary: While all Chinese words are unique, the English translation yielded around 25000 duplicated entries. This means that users searching for example for "satellite" will find hits for 卫星, 颗卫星 and 人造卫星, which all carry that meaning, improving the accuracy of text mining.


## Economic data retrieval (Eyayaw)

- Where, what and how did we get it.

- This can be very short.


## Exploratory statistics, visualisation, and text mining (Eyayaw)
Start with simplest descriptives and plots, e.g.:

- descriptive plots for the data: article frequencies etc.
The data reveal that there are systematic differences between the first and second pages. ((insert article frequency plots from descriptives))
For both 2019 and 2020, the first page has several outliers with over 10 articles per page, while the second page has no more than 9 articles per page. This is mostly due to the coverage over important events which are covered in many small articles on the front page, e.g Xi Jinping's meetings with world leaders at international summits.

- most common non-stop words with frequencies

- compare pre- and post-corona common words

- pre-post word clouds with translated words

- two-word correlation

- time-series frequency plots (very important)


Optional:

- bigram graph

- two-word correlation with phi-coefficient

- lda/topic model (very optional)

Do not:

- sentiment analysis


## Shiny user interface (David)



# Results

Here we should show some of the results of our application. As discussed before COVID-19 will be most likely the centre of our examples but maybe we can show here the mentioned theory of the shadow page as well



# Discussion

How could we improve the app? Extend the archive? Add more economic data? Implement some other statistical information?

Encrypted server version



# Conclusion

Summary of our application and our results. Do we have plans to expand and update the app further in the near future?



Just an idea, because they want it scientific, let's include a bunch of references to the data mining book, etc., just if you find some that would make sense.

\newpage











